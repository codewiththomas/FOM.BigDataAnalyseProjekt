# ResearchRAG Baseline Configuration
# This configuration uses GPT-4o-mini as the baseline model

llm:
  type: openai
  model: gpt-4o-mini
  temperature: 0.1
  max_tokens: 1000
  # api_key: ${OPENAI_API_KEY}  # Set via environment variable

embedding:
  # type: openai
  # model: text-embedding-ada-002
  type: sentence-transformers # <- für Angleichung embeddings zwischen mixtral und baseline
  model_name: all-MiniLM-L6-v2 # <- für Angleichung embeddings zwischen mixtral und baseline
  # model_name: all-mpnet-base-v2 # besser als all-MiniLM-L6-v2
  device: cuda
  batch_size: 128 # cuda-optimiert für bessere Performance

chunking:
  type: fixed-size
  chunk_size: 1500
  chunk_overlap: 200
  separator: "\n"

retrieval:
  type: vector-similarity
  top_k: 5
  similarity_threshold: 0.00

evaluation:
  enabled_metrics:
    - precision-recall
    - timing
    - ragas

dataset:
  evaluation_subset_size: 100 # Legt fest, wieviele QA-Paare aus dem Dataset für die Evaluation verwendet werden
  save_qa_pairs: true
  grouping:
    enabled: true # false für Deaktivierung der Gruppierung

pipeline:
  include_context: true
  max_context_length: 3500 # Empfehlung: top_k * chunksize / 4 (Umrechnung char zu token)
