#!/bin/bash
# ResearchRAG Lokales Setup-Skript

echo "ðŸš€ ResearchRAG Lokales Setup"
echo "=============================="

# 1. Dependencies installieren
echo "ðŸ“¦ Installiere Python-Dependencies..."
pip install sentence-transformers chromadb faiss-cpu requests

# 2. Ollama installieren (falls nicht vorhanden)
if ! command -v ollama &> /dev/null; then
    echo "ðŸ¦™ Installiere Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
else
    echo "âœ… Ollama bereits installiert"
fi

# 3. Ollama starten (im Hintergrund)
echo "ðŸ”§ Starte Ollama-Service..."
ollama serve &
OLLAMA_PID=$!
sleep 5

# 4. Llama3.2 Modell laden
echo "ðŸ“¥ Lade llama3.2 Modell..."
ollama pull llama3.2

echo "âœ… Setup abgeschlossen!"
echo ""
echo "ðŸ§ª Teste das System mit:"
echo "   python test_local_rag.py"
echo ""
echo "ðŸ›‘ Stoppe Ollama mit:"
echo "   kill $OLLAMA_PID"