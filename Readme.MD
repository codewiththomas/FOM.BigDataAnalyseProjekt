# Forschungs-RAG-System fÃ¼r Big Data Analyse

Ein modulares, erweiterbares RAG-System (Retrieval-Augmented Generation) fÃ¼r Forschungszwecke mit DSGVO-Daten.

## ğŸ¯ Projektziel

Dieses System ermÃ¶glicht die systematische Evaluierung verschiedener RAG-Komponenten:

- **Chunker**: Line Chunker vs. Recursive Character Chunker
- **Embeddings**: OpenAI Embeddings vs. lokale Sentence Transformers
- **Vector Stores**: In-Memory vs. Chroma DB
- **Language Models**: OpenAI LLM vs. lokale Small Language Models (SLM)

## ğŸ“Š Evaluierungsmetriken

- **Precision, Recall, F1-Score**
- **RAGAS-Metriken** (Context Relevance, Answer Relevance, Faithfulness)
- **Mean Reciprocal Rank (MRR)**
- **Normalized Discounted Cumulative Gain (nDCG)**

## ğŸ—ï¸ Systemarchitektur

```
src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ chunkers/           # Text-Aufteilung
â”‚   â”‚   â”œâ”€â”€ base_chunker.py
â”‚   â”‚   â”œâ”€â”€ line_chunker.py
â”‚   â”‚   â””â”€â”€ recursive_chunker.py
â”‚   â”œâ”€â”€ embeddings/         # Text-Vektorisierung
â”‚   â”‚   â”œâ”€â”€ base_embedding.py
â”‚   â”‚   â”œâ”€â”€ sentence_transformer_embedding.py
â”‚   â”‚   â””â”€â”€ openai_embedding.py
â”‚   â”œâ”€â”€ vector_stores/      # Vektorspeicherung
â”‚   â”‚   â”œâ”€â”€ base_vector_store.py
â”‚   â”‚   â”œâ”€â”€ in_memory_vector_store.py
â”‚   â”‚   â””â”€â”€ chroma_vector_store.py
â”‚   â””â”€â”€ language_models/    # Antwortgenerierung
â”‚       â”œâ”€â”€ base_language_model.py
â”‚       â”œâ”€â”€ openai_language_model.py
â”‚       â””â”€â”€ local_language_model.py
â”œâ”€â”€ config/                 # Konfiguration
â”œâ”€â”€ evaluations/            # Evaluierung
â”œâ”€â”€ experiments/            # Experimente
â””â”€â”€ data_loader.py          # Datenverarbeitung
```

## ğŸš€ Schnellstart

### 1. Umgebung einrichten

```bash
# Repository klonen
git clone <repository-url>
cd FOM.BigDataAnalyseProjekt

# Python-Umgebung erstellen
python -m venv .venv

# Umgebung aktivieren (Windows)
.\.venv\Scripts\Activate

# Umgebung aktivieren (Linux/Mac)
source .venv/bin/activate

# AbhÃ¤ngigkeiten installieren
pip install -r requirements.txt
```

### 2. OpenAI API Key konfigurieren

Erstellen Sie eine `.env`-Datei im Hauptverzeichnis:

```env
OPENAI_API_KEY=your-openai-api-key-here
```

### 3. Experimente ausfÃ¼hren

```bash
# VollstÃ¤ndige Experimente mit DSGVO-Daten
python run_experiments.py
```

### 4. Jupyter Notebook verwenden

```bash
# Jupyter starten
jupyter notebook src/rag.ipynb
```

## ğŸ“‹ VerfÃ¼gbare Komponenten

### Chunker

- **Line Chunker**: Einfache Zeilen-basierte Aufteilung
- **Recursive Character Chunker**: Intelligente Aufteilung mit Overlap

### Embeddings

- **Sentence Transformers**: Lokale Embeddings (all-MiniLM-L6-v2)
- **OpenAI Embeddings**: Cloud-basierte Embeddings (text-embedding-ada-002)

### Vector Stores

- **In-Memory**: Schneller Speicher fÃ¼r kleine DatensÃ¤tze
- **Chroma DB**: Persistente, skalierbare Vektordatenbank

### Language Models

- **OpenAI GPT**: Cloud-basierte Antwortgenerierung
- **Lokale SLMs**: Ollama/LLaMA2 Integration

## ğŸ”¬ Experimente

Das System fÃ¼hrt automatisch Experimente mit verschiedenen Konfigurationen durch:

1. **Baseline**: Line Chunker + Sentence Transformers + In-Memory + OpenAI
2. **Recursive Chunker**: Verbesserte Textaufteilung
3. **OpenAI Embeddings**: Cloud-basierte Vektorisierung
4. **Chroma Vector Store**: Persistente Speicherung
5. **Lokales LLM**: Offline-Verarbeitung
6. **Beste Kombination**: Optimierte Konfiguration

## ğŸ“Š Ergebnisse

Experimente werden automatisch gespeichert in:
- `experiment_results/` - JSON-Dateien mit detaillierten Ergebnissen
- `experiment_report.md` - Markdown-Bericht mit Vergleich

## ğŸ› ï¸ Entwicklung

### Neue Komponenten hinzufÃ¼gen

1. **Chunker**: Erweitern Sie `BaseChunker`
2. **Embeddings**: Erweitern Sie `BaseEmbedding`
3. **Vector Stores**: Erweitern Sie `BaseVectorStore`
4. **Language Models**: Erweitern Sie `BaseLanguageModel`

### Beispiel fÃ¼r neue Komponente

```python
from src.components.chunkers.base_chunker import BaseChunker

class MyCustomChunker(BaseChunker):
    def chunk_text(self, text: str) -> List[str]:
        # Ihre Implementierung hier
        pass
```

## ğŸ“ˆ Evaluierung

### Automatische Metriken

- **Retrieval-Metriken**: Precision@k, Recall@k, F1@k, MRR, nDCG
- **Generation-Metriken**: Relevanz, Treue, Korrektheit
- **System-Metriken**: AntwortlÃ¤nge, Erfolgsrate, Fehlerrate

### Manuelle Evaluierung

```python
from src.evaluations.rag_metrics import RAGMetrics

metrics = RAGMetrics()
results = metrics.evaluate_rag_system(
    queries=test_questions,
    retrieved_docs=retrieved_documents,
    answers=generated_answers
)
```

## ğŸ“š DSGVO-Daten

Das System verwendet die vollstÃ¤ndige DSGVO-Verordnung als Testdaten:

- **Quelle**: `data/raw/dsgvo.txt`
- **GrÃ¶ÃŸe**: ~400KB, 3633 Zeilen
- **Struktur**: Artikel-basierte Aufteilung
- **Testfragen**: 20 DSGVO-spezifische Fragen

## ğŸ”§ Konfiguration

### RAGConfig

```python
from src.config import RAGConfig

config = RAGConfig(
    chunker_type="recursive",
    chunker_params={"chunk_size": 1000, "chunk_overlap": 200},
    embedding_type="openai",
    embedding_params={"model": "text-embedding-ada-002"},
    vector_store_type="chroma",
    vector_store_params={"persist_directory": "./chroma_db"},
    language_model_type="openai",
    language_model_params={"api_key": "your-key"}
)
```

## ğŸ§ª Testing

```bash
# Unit Tests
pytest tests/unit/

# Integration Tests
pytest tests/integration/

# End-to-End Tests
pytest tests/e2e/
```

## ğŸ“– Dokumentation

```bash
# Dokumentation generieren
mkdocs serve
```

## ğŸ¤ Beitragen

1. Fork das Repository
2. Erstellen Sie einen Feature Branch
3. Implementieren Sie Ihre Ã„nderungen
4. FÃ¼gen Sie Tests hinzu
5. Erstellen Sie einen Pull Request

## ğŸ“„ Lizenz

Dieses Projekt ist fÃ¼r Forschungszwecke konzipiert.

## ğŸ†˜ Support

Bei Fragen oder Problemen:
1. ÃœberprÃ¼fen Sie die Dokumentation
2. Schauen Sie in die Issues
3. Erstellen Sie ein neues Issue mit detaillierter Beschreibung

---

**Entwickelt fÃ¼r das FOM Big Data Analyseprojekt** ğŸ“
