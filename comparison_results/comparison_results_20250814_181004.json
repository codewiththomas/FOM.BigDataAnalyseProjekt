{
  "baseline": {
    "avg_precision": 0.1456323273412197,
    "min_precision": 0.1055031525851198,
    "max_precision": 0.21081488207011823,
    "avg_recall": 0.22485166158654576,
    "min_recall": 0.12809138787923746,
    "max_recall": 0.3957670024531552,
    "avg_f1": 0.17492174473666455,
    "min_f1": 0.1157051463052064,
    "max_f1": 0.2750941829229815,
    "avg_query_time": 2.122884511947632,
    "min_query_time": 1.3031117916107178,
    "max_query_time": 2.9121150970458984,
    "avg_response_length": 286.0,
    "min_response_length": 208,
    "max_response_length": 436,
    "avg_faithfulness": 0.3249612403100775,
    "min_faithfulness": 0.2,
    "max_faithfulness": 0.5348837209302325,
    "avg_answer_relevance": 0.20377394636015325,
    "min_answer_relevance": 0.14666666666666667,
    "max_answer_relevance": 0.275,
    "avg_context_relevance": 0.19648148148148148,
    "min_context_relevance": 0.04444444444444444,
    "max_context_relevance": 0.325,
    "pipeline_info": {
      "llm": {
        "name": "openai-gpt-4o-mini",
        "provider": "openai",
        "model": "gpt-4o-mini",
        "temperature": 0.1,
        "max_tokens": 1000
      },
      "embedding": {
        "name": "openai-text-embedding-ada-002",
        "provider": "openai",
        "model": "text-embedding-ada-002",
        "dimensions": 1536
      },
      "chunking": {
        "name": "fixedsizechunking-chunking",
        "strategy": 1000,
        "chunk_size": 1000,
        "chunk_overlap": 200,
        "separator": "\n"
      },
      "retrieval": {
        "name": "vector-similarity-retrieval",
        "method": "cosine_similarity",
        "chunks_indexed": 988,
        "top_k": 5,
        "similarity_threshold": 0.0,
        "embedding_dimensions": 1536
      },
      "is_indexed": true
    },
    "evaluation_info": {
      "enabled_evaluators": [
        "PrecisionRecallEvaluator",
        "TimingEvaluator",
        "RAGASEvaluator"
      ],
      "total_metrics": 22
    },
    "total_evaluation_time": 6.371026039123535,
    "qa_pairs_evaluated": 3
  },
  "mixtral_7b": {
    "avg_precision": 0.024852071005917162,
    "min_precision": 0.024852071005917162,
    "max_precision": 0.024852071005917162,
    "avg_recall": 0.024852071005917162,
    "min_recall": 0.024852071005917162,
    "max_recall": 0.024852071005917162,
    "avg_f1": 0.024852071005917162,
    "min_f1": 0.024852071005917162,
    "max_f1": 0.024852071005917162,
    "avg_query_time": 62.06790693600973,
    "min_query_time": 62.05469560623169,
    "max_query_time": 62.08880090713501,
    "avg_response_length": 17.0,
    "min_response_length": 17,
    "max_response_length": 17,
    "avg_faithfulness": 0.0,
    "min_faithfulness": 0.0,
    "max_faithfulness": 0.0,
    "avg_answer_relevance": 0.0,
    "min_answer_relevance": 0.0,
    "max_answer_relevance": 0.0,
    "avg_context_relevance": 0.14981481481481482,
    "min_context_relevance": 0.04444444444444444,
    "max_context_relevance": 0.225,
    "pipeline_info": {
      "llm": {
        "name": "mixtral:8x7b",
        "provider": "local",
        "endpoint": "http://localhost:11434",
        "api_type": "ollama",
        "temperature": 0.1,
        "max_tokens": 1000
      },
      "embedding": {
        "name": "sentence-transformers-all-MiniLM-L6-v2",
        "provider": "sentence-transformers",
        "model": "all-MiniLM-L6-v2",
        "device": "cpu",
        "dimensions": 384
      },
      "chunking": {
        "name": "fixedsizechunking-chunking",
        "strategy": 1000,
        "chunk_size": 1000,
        "chunk_overlap": 200,
        "separator": "\n"
      },
      "retrieval": {
        "name": "vector-similarity-retrieval",
        "method": "cosine_similarity",
        "chunks_indexed": 988,
        "top_k": 5,
        "similarity_threshold": 0.0,
        "embedding_dimensions": 384
      },
      "is_indexed": true
    },
    "evaluation_info": {
      "enabled_evaluators": [
        "PrecisionRecallEvaluator",
        "TimingEvaluator",
        "RAGASEvaluator"
      ],
      "total_metrics": 22
    },
    "total_evaluation_time": 186.20715284347534,
    "qa_pairs_evaluated": 3
  }
}