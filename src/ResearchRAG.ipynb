{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ResearchRAG - Modulares RAG-System\n",
        "\n",
        "Dieses Notebook steuert das modulare RAG-System f√ºr die wissenschaftliche Studie.\n",
        "\n",
        "## üéØ √úberblick\n",
        "\n",
        "- **Zweck**: Vergleich verschiedener RAG-Komponenten\n",
        "- **Team**: 4 Personen, 30 Tage\n",
        "- **Daten**: DSGVO-Text\n",
        "- **Ziel**: Systematische Evaluation verschiedener Ans√§tze\n",
        "\n",
        "## üìã Notebook-Struktur\n",
        "\n",
        "1. **Setup & Installation** - Abh√§ngigkeiten und Umgebung\n",
        "2. **Konfiguration** - Pipeline-Konfigurationen ausw√§hlen\n",
        "3. **Datenloading** - DSGVO-Dokumente laden\n",
        "4. **Pipeline-Erstellung** - RAG-Pipeline initialisieren\n",
        "5. **Indexierung** - Dokumente verarbeiten und indexieren\n",
        "6. **Querying** - Interaktive Abfragen\n",
        "7. **Evaluation** - Systematische Bewertung\n",
        "8. **Analyse** - Komponenten-Vergleich und Statistiken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Setup & Installation\n",
        "\n",
        "## Google Colab Setup\n",
        "\n",
        "Falls Sie in Google Colab arbeiten, f√ºhren Sie zuerst diese Zellen aus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Colab Setup - nur ausf√ºhren wenn in Colab\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Pr√ºfen ob wir in Google Colab sind\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"üîß Google Colab erkannt - Setup wird gestartet...\")\n",
        "    \n",
        "    # Google Drive mounten f√ºr Persistierung\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    # Arbeitsverzeichnis erstellen\n",
        "    project_dir = '/content/drive/MyDrive/FOM_RAG_Project'\n",
        "    if not os.path.exists(project_dir):\n",
        "        os.makedirs(project_dir)\n",
        "    os.chdir(project_dir)\n",
        "    \n",
        "    # Projekt-Repository klonen (falls noch nicht vorhanden)\n",
        "    if not os.path.exists('src'):\n",
        "        print(\"üì• Lade Projekt-Code...\")\n",
        "        # Hier w√ºrden Sie normalerweise das Repository klonen\n",
        "        # !git clone https://github.com/your-repo/FOM.BigDataAnalyseProjekt.git .\n",
        "        print(\"‚ö†Ô∏è  Bitte laden Sie die Projekt-Dateien manuell hoch\")\n",
        "    \n",
        "    print(\"‚úÖ Google Colab Setup abgeschlossen\")\n",
        "    print(f\"üìÅ Arbeitsverzeichnis: {os.getcwd()}\")\n",
        "else:\n",
        "    print(\"üíª Lokale Umgebung erkannt\")\n",
        "    print(f\"üìÅ Arbeitsverzeichnis: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Package Installation\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package):\n",
        "    \"\"\"Installiert ein Package falls nicht vorhanden.\"\"\"\n",
        "    try:\n",
        "        __import__(package.split('>=')[0].split('==')[0])\n",
        "        print(f\"‚úÖ {package} bereits installiert\")\n",
        "    except ImportError:\n",
        "        print(f\"üì¶ Installiere {package}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "        print(f\"‚úÖ {package} installiert\")\n",
        "\n",
        "# Kern-Abh√§ngigkeiten installieren\n",
        "core_packages = [\n",
        "    \"numpy>=1.24.0\",\n",
        "    \"pandas>=2.0.0\", \n",
        "    \"scikit-learn>=1.3.0\",\n",
        "    \"openai>=1.0.0\",\n",
        "    \"tqdm>=4.65.0\",\n",
        "    \"python-dotenv>=1.0.0\",\n",
        "    \"matplotlib>=3.7.0\",\n",
        "    \"seaborn>=0.12.0\"\n",
        "]\n",
        "\n",
        "print(\"üîß Installiere Kern-Abh√§ngigkeiten...\")\n",
        "for package in core_packages:\n",
        "    install_package(package)\n",
        "\n",
        "print(\"‚úÖ Alle Abh√§ngigkeiten installiert!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Umgebungsvariablen und API-Schl√ºssel\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import getpass\n",
        "\n",
        "# .env Datei laden (falls vorhanden)\n",
        "load_dotenv()\n",
        "\n",
        "# OpenAI API Key setup\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    print(\"üîë OpenAI API Key erforderlich\")\n",
        "    print(\"Sie k√∂nnen den Key auf verschiedene Weise setzen:\")\n",
        "    print(\"1. √úber .env Datei: OPENAI_API_KEY=your_key_here\")\n",
        "    print(\"2. √úber Umgebungsvariable: export OPENAI_API_KEY=your_key_here\")\n",
        "    print(\"3. Hier direkt eingeben (nur f√ºr Tests!):\")\n",
        "    \n",
        "    api_key = getpass.getpass(\"OpenAI API Key eingeben (wird versteckt): \")\n",
        "    if api_key:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "        print(\"‚úÖ API Key gesetzt\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  Kein API Key eingegeben - OpenAI-Komponenten werden nicht funktionieren\")\n",
        "else:\n",
        "    print(\"‚úÖ OpenAI API Key gefunden\")\n",
        "\n",
        "# Andere Umgebungsvariablen\n",
        "print(\"\\nüìã Aktuelle Umgebung:\")\n",
        "print(f\"  Python Version: {sys.version}\")\n",
        "print(f\"  Arbeitsverzeichnis: {os.getcwd()}\")\n",
        "print(f\"  OpenAI API Key: {'‚úÖ Gesetzt' if os.getenv('OPENAI_API_KEY') else '‚ùå Nicht gesetzt'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Konfiguration\n",
        "\n",
        "## Pipeline-Konfigurationen ausw√§hlen\n",
        "\n",
        "Hier k√∂nnen Sie verschiedene Konfigurationen f√ºr Ihr Experiment ausw√§hlen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports f√ºr das RAG-System\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Pfad zum src-Verzeichnis hinzuf√ºgen\n",
        "if 'src' not in sys.path:\n",
        "    sys.path.append('src')\n",
        "\n",
        "# RAG-System Imports\n",
        "from config.pipeline_configs import get_baseline_config, get_alternative_configs\n",
        "from config.experiment_configs import get_experiment_configs\n",
        "from core.rag_pipeline import RAGPipeline\n",
        "from utils.data_loader import DataLoader\n",
        "\n",
        "print(\"‚úÖ RAG-System Module importiert\")\n",
        "\n",
        "# Verf√ºgbare Konfigurationen anzeigen\n",
        "print(\"\\nüìã Verf√ºgbare Pipeline-Konfigurationen:\")\n",
        "\n",
        "# Baseline-Konfiguration\n",
        "baseline_config = get_baseline_config()\n",
        "print(f\"\\nüîπ Baseline: {baseline_config.get_component_types()}\")\n",
        "\n",
        "# Alternative Konfigurationen\n",
        "alternative_configs = get_alternative_configs()\n",
        "for name, config in alternative_configs.items():\n",
        "    print(f\"üîπ {name}: {config.get_component_types()}\")\n",
        "\n",
        "print(f\"\\nüìä Insgesamt {1 + len(alternative_configs)} Konfigurationen verf√ºgbar\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Konfiguration ausw√§hlen\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Dropdown f√ºr Konfigurationsauswahl\n",
        "config_names = [\"baseline\"] + list(alternative_configs.keys())\n",
        "config_dropdown = widgets.Dropdown(\n",
        "    options=config_names,\n",
        "    value=\"baseline\",\n",
        "    description=\"Konfiguration:\",\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "# Aktuelle Konfiguration anzeigen\n",
        "config_output = widgets.Output()\n",
        "\n",
        "def on_config_change(change):\n",
        "    with config_output:\n",
        "        clear_output()\n",
        "        config_name = change['new']\n",
        "        \n",
        "        if config_name == \"baseline\":\n",
        "            selected_config = baseline_config\n",
        "        else:\n",
        "            selected_config = alternative_configs[config_name]\n",
        "        \n",
        "        print(f\"üìã Gew√§hlte Konfiguration: {config_name}\")\n",
        "        print(f\"üîß Komponenten: {selected_config.get_component_types()}\")\n",
        "        \n",
        "        # Detaillierte Konfiguration anzeigen\n",
        "        print(\"\\nüìÑ Detaillierte Konfiguration:\")\n",
        "        for component_type in [\"chunker\", \"embedding\", \"vector_store\", \"language_model\"]:\n",
        "            config_method = getattr(selected_config, f\"get_{component_type}_config\")\n",
        "            component_config = config_method()\n",
        "            print(f\"  {component_type}: {component_config}\")\n",
        "\n",
        "config_dropdown.observe(on_config_change, names='value')\n",
        "\n",
        "# Initial anzeigen\n",
        "on_config_change({'new': config_dropdown.value})\n",
        "\n",
        "display(config_dropdown, config_output)\n",
        "\n",
        "# Aktuelle Konfiguration f√ºr sp√§tere Verwendung speichern\n",
        "def get_current_config():\n",
        "    config_name = config_dropdown.value\n",
        "    if config_name == \"baseline\":\n",
        "        return baseline_config\n",
        "    else:\n",
        "        return alternative_configs[config_name]\n",
        "\n",
        "print(\"\\n‚úÖ Konfiguration bereit - verwenden Sie get_current_config() um die aktuelle Konfiguration zu erhalten\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Datenloading\n",
        "\n",
        "## DSGVO-Dokumente laden\n",
        "\n",
        "Hier laden wir die DSGVO-Dokumente, die als Basis f√ºr unser RAG-System dienen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Datenverzeichnis pr√ºfen und erstellen\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Datenverzeichnis-Struktur erstellen\n",
        "data_dirs = [\n",
        "    \"data/raw\",\n",
        "    \"data/processed/chunks\", \n",
        "    \"data/processed/embeddings\",\n",
        "    \"data/evaluation/results\"\n",
        "]\n",
        "\n",
        "for dir_path in data_dirs:\n",
        "    Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Datenverzeichnisse erstellt\")\n",
        "\n",
        "# DSGVO-Datei pr√ºfen\n",
        "dsgvo_file = \"data/raw/dsgvo.txt\"\n",
        "\n",
        "if os.path.exists(dsgvo_file):\n",
        "    with open(dsgvo_file, 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "    \n",
        "    print(f\"üìÑ DSGVO-Datei gefunden: {dsgvo_file}\")\n",
        "    print(f\"üìä Dateigr√∂√üe: {len(content):,} Zeichen\")\n",
        "    print(f\"üìù Erste 200 Zeichen:\")\n",
        "    print(content[:200] + \"...\")\n",
        "    \n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  DSGVO-Datei nicht gefunden: {dsgvo_file}\")\n",
        "    print(\"üí° Bitte laden Sie die DSGVO-Datei in das data/raw/ Verzeichnis\")\n",
        "    print(\"üì• Sie k√∂nnen sie hier herunterladen: https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX%3A32016R0679\")\n",
        "    \n",
        "    # Beispiel-Inhalt f√ºr Testzwecke\n",
        "    sample_content = \"\"\"\n",
        "    VERORDNUNG (EU) 2016/679 DES EUROP√ÑISCHEN PARLAMENTS UND DES RATES\n",
        "    \n",
        "    Artikel 1 - Gegenstand und Ziele\n",
        "    \n",
        "    (1) Diese Verordnung enth√§lt Vorschriften zum Schutz nat√ºrlicher Personen bei der Verarbeitung personenbezogener Daten und zum freien Verkehr solcher Daten.\n",
        "    \n",
        "    (2) Diese Verordnung sch√ºtzt die Grundrechte und Grundfreiheiten nat√ºrlicher Personen und insbesondere deren Recht auf Schutz personenbezogener Daten.\n",
        "    \n",
        "    Artikel 83 - Allgemeine Bedingungen f√ºr die Verh√§ngung von Geldbu√üen\n",
        "    \n",
        "    (1) Jede Aufsichtsbeh√∂rde stellt sicher, dass die Verh√§ngung von Geldbu√üen gem√§√ü diesem Artikel f√ºr Verst√∂√üe gegen diese Verordnung gem√§√ü den Abs√§tzen 4, 5 und 6 in jedem Einzelfall wirksam, verh√§ltnism√§√üig und abschreckend ist.\n",
        "    \n",
        "    (5) Verst√∂√üe gegen die folgenden Bestimmungen werden im Einklang mit Absatz 2 mit Geldbu√üen von bis zu 20 000 000 EUR oder im Fall eines Unternehmens von bis zu 4 % seines gesamten weltweit erzielten Jahresumsatzes des vorangegangenen Gesch√§ftsjahrs verh√§ngt, je nachdem, welcher Betrag h√∂her ist:\n",
        "    \"\"\"\n",
        "    \n",
        "    # Beispiel-Datei erstellen\n",
        "    with open(dsgvo_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(sample_content)\n",
        "    \n",
        "    print(f\"üìù Beispiel-DSGVO-Datei erstellt: {dsgvo_file}\")\n",
        "    print(\"‚ö†Ô∏è  Dies ist nur ein Beispiel - bitte ersetzen Sie durch die vollst√§ndige DSGVO\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Pipeline-Erstellung\n",
        "\n",
        "## RAG-Pipeline initialisieren\n",
        "\n",
        "Hier erstellen wir die RAG-Pipeline mit der gew√§hlten Konfiguration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RAG-Pipeline erstellen\n",
        "import time\n",
        "\n",
        "print(\"üîß Erstelle RAG-Pipeline...\")\n",
        "\n",
        "# Aktuelle Konfiguration laden\n",
        "current_config = get_current_config()\n",
        "print(f\"üìã Verwende Konfiguration: {current_config.get_component_types()}\")\n",
        "\n",
        "# Pipeline initialisieren\n",
        "try:\n",
        "    start_time = time.time()\n",
        "    pipeline = RAGPipeline(current_config)\n",
        "    init_time = time.time() - start_time\n",
        "    \n",
        "    print(f\"‚úÖ Pipeline erfolgreich erstellt in {init_time:.2f}s\")\n",
        "    \n",
        "    # Pipeline-Informationen anzeigen\n",
        "    pipeline_info = pipeline.get_pipeline_info()\n",
        "    print(f\"\\nüìä Pipeline-Informationen:\")\n",
        "    print(f\"  Status: {'üü¢ Bereit' if pipeline else 'üî¥ Fehler'}\")\n",
        "    print(f\"  Indexiert: {'‚úÖ Ja' if pipeline.is_indexed else '‚ùå Nein'}\")\n",
        "    print(f\"  Dokumente: {pipeline.indexed_document_count}\")\n",
        "    \n",
        "    # Komponenten-Informationen\n",
        "    component_info = pipeline.get_component_info()\n",
        "    print(f\"\\nüîß Komponenten-Details:\")\n",
        "    for component, info in component_info.items():\n",
        "        print(f\"  {component}: {info}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Fehler beim Erstellen der Pipeline: {e}\")\n",
        "    print(\"üí° Pr√ºfen Sie:\")\n",
        "    print(\"  - OpenAI API Key ist gesetzt\")\n",
        "    print(\"  - Alle Abh√§ngigkeiten sind installiert\")\n",
        "    print(\"  - Konfiguration ist korrekt\")\n",
        "    \n",
        "    # Traceback f√ºr Debugging\n",
        "    import traceback\n",
        "    print(f\"\\nüêõ Detaillierter Fehler:\")\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Indexierung\n",
        "\n",
        "## Dokumente verarbeiten und indexieren\n",
        "\n",
        "Hier werden die DSGVO-Dokumente in die Pipeline geladen und indexiert.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dokumente laden und indexieren\n",
        "import time\n",
        "\n",
        "if 'pipeline' not in locals():\n",
        "    print(\"‚ùå Pipeline nicht verf√ºgbar - bitte f√ºhren Sie zuerst die Pipeline-Erstellung aus\")\n",
        "else:\n",
        "    print(\"üì• Lade DSGVO-Dokumente...\")\n",
        "    \n",
        "    try:\n",
        "        # Dokumente aus Datei laden\n",
        "        documents = pipeline.load_documents_from_file(dsgvo_file)\n",
        "        print(f\"‚úÖ {len(documents)} Dokument(e) geladen\")\n",
        "        \n",
        "        # Indexierung starten\n",
        "        print(\"\\nüîÑ Starte Indexierung...\")\n",
        "        print(\"  Dies kann einige Minuten dauern, abh√§ngig von der Dokumentgr√∂√üe und den gew√§hlten Komponenten\")\n",
        "        \n",
        "        start_time = time.time()\n",
        "        indexing_stats = pipeline.index_documents(documents, show_progress=True)\n",
        "        total_time = time.time() - start_time\n",
        "        \n",
        "        print(f\"\\n‚úÖ Indexierung abgeschlossen!\")\n",
        "        print(f\"‚è±Ô∏è  Gesamtzeit: {total_time:.2f}s\")\n",
        "        \n",
        "        # Detaillierte Statistiken\n",
        "        print(f\"\\nüìä Indexierungs-Statistiken:\")\n",
        "        print(f\"  üìÑ Dokumente: {indexing_stats['total_documents']}\")\n",
        "        print(f\"  üìù Chunks: {indexing_stats['total_chunks']}\")\n",
        "        print(f\"  üî¢ Embeddings: {indexing_stats['total_embeddings']}\")\n",
        "        print(f\"  üìè Embedding-Dimension: {indexing_stats['embedding_dimension']}\")\n",
        "        print(f\"  ‚ö° Chunks/Sekunde: {indexing_stats['chunks_per_second']:.1f}\")\n",
        "        print(f\"  üìê √ò Chunk-L√§nge: {indexing_stats['average_chunk_length']:.0f} Zeichen\")\n",
        "        \n",
        "        # Speichernutzung (gesch√§tzt)\n",
        "        embedding_size_mb = (indexing_stats['total_embeddings'] * indexing_stats['embedding_dimension'] * 4) / (1024 * 1024)\n",
        "        print(f\"  üíæ Gesch√§tzte Embedding-Gr√∂√üe: {embedding_size_mb:.1f} MB\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Fehler bei der Indexierung: {e}\")\n",
        "        print(\"üí° M√∂gliche Ursachen:\")\n",
        "        print(\"  - Datei nicht gefunden oder nicht lesbar\")\n",
        "        print(\"  - OpenAI API Fehler (Rate Limit, Authentifizierung)\")\n",
        "        print(\"  - Speicher-/Netzwerkprobleme\")\n",
        "        \n",
        "        import traceback\n",
        "        print(f\"\\nüêõ Detaillierter Fehler:\")\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Querying\n",
        "\n",
        "## Interaktive Abfragen\n",
        "\n",
        "Jetzt k√∂nnen Sie Fragen zur DSGVO stellen und die Antworten des RAG-Systems testen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Beispiel-Abfragen\n",
        "example_questions = [\n",
        "    \"Was ist die maximale Geldbu√üe nach Art. 83 DSGVO?\",\n",
        "    \"Welche Rechte haben betroffene Personen?\",\n",
        "    \"Was ist eine Datenschutz-Folgenabsch√§tzung?\",\n",
        "    \"Wann ist eine Einwilligung erforderlich?\",\n",
        "    \"Was sind die Grunds√§tze der Datenverarbeitung?\"\n",
        "]\n",
        "\n",
        "print(\"üîç Beispiel-Fragen zur DSGVO:\")\n",
        "for i, question in enumerate(example_questions, 1):\n",
        "    print(f\"  {i}. {question}\")\n",
        "\n",
        "print(\"\\nüí° Sie k√∂nnen diese Fragen verwenden oder eigene stellen\")\n",
        "\n",
        "# Funktion f√ºr einzelne Abfragen\n",
        "def ask_question(question, top_k=5, return_context=False):\n",
        "    \"\"\"Stellt eine Frage an die RAG-Pipeline.\"\"\"\n",
        "    if 'pipeline' not in locals() and 'pipeline' not in globals():\n",
        "        print(\"‚ùå Pipeline nicht verf√ºgbar\")\n",
        "        return None\n",
        "    \n",
        "    if not pipeline.is_indexed:\n",
        "        print(\"‚ùå Pipeline ist nicht indexiert\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"‚ùì Frage: {question}\")\n",
        "    print(\"üîÑ Verarbeite...\")\n",
        "    \n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        result = pipeline.query(question, top_k=top_k, return_context=return_context)\n",
        "        query_time = time.time() - start_time\n",
        "        \n",
        "        print(f\"\\n‚úÖ Antwort (in {query_time:.2f}s):\")\n",
        "        print(f\"üìù {result['answer']}\")\n",
        "        \n",
        "        if return_context:\n",
        "            print(f\"\\nüìö Verwendete Quellen ({len(result['context'])}):\")\n",
        "            for i, context in enumerate(result['context'], 1):\n",
        "                print(f\"  {i}. {context[:100]}...\")\n",
        "        \n",
        "        print(f\"\\nüìä Metadaten:\")\n",
        "        print(f\"  ‚è±Ô∏è  Query-Zeit: {query_time:.2f}s\")\n",
        "        print(f\"  üîç Retrieval-Zeit: {result['retrieval_time']:.2f}s\")\n",
        "        print(f\"  ü§ñ Generation-Zeit: {result['generation_time']:.2f}s\")\n",
        "        print(f\"  üìÑ Gefundene Dokumente: {len(result['context'])}\")\n",
        "        \n",
        "        return result\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Fehler bei der Abfrage: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "print(\"\\n‚úÖ Abfrage-Funktion bereit - verwenden Sie ask_question('Ihre Frage hier')\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interaktive Abfrage-Widgets\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Text-Input f√ºr Fragen\n",
        "question_input = widgets.Text(\n",
        "    value=\"Was ist die maximale Geldbu√üe nach Art. 83 DSGVO?\",\n",
        "    placeholder=\"Stellen Sie hier Ihre Frage zur DSGVO...\",\n",
        "    description=\"Frage:\",\n",
        "    layout=widgets.Layout(width='80%')\n",
        ")\n",
        "\n",
        "# Optionen\n",
        "top_k_slider = widgets.IntSlider(\n",
        "    value=5,\n",
        "    min=1,\n",
        "    max=20,\n",
        "    step=1,\n",
        "    description=\"Top-K:\",\n",
        "    tooltip=\"Anzahl der zu retrievenden Dokumente\"\n",
        ")\n",
        "\n",
        "show_context_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description=\"Kontext anzeigen\",\n",
        "    tooltip=\"Zeigt die verwendeten Quellen an\"\n",
        ")\n",
        "\n",
        "# Button f√ºr Abfrage\n",
        "query_button = widgets.Button(\n",
        "    description=\"Frage stellen\",\n",
        "    button_style='primary',\n",
        "    icon='search'\n",
        ")\n",
        "\n",
        "# Output-Bereich\n",
        "query_output = widgets.Output()\n",
        "\n",
        "def on_query_button_click(b):\n",
        "    \"\"\"Behandelt Button-Klicks f√ºr Abfragen.\"\"\"\n",
        "    with query_output:\n",
        "        clear_output()\n",
        "        question = question_input.value.strip()\n",
        "        \n",
        "        if not question:\n",
        "            print(\"‚ùå Bitte geben Sie eine Frage ein\")\n",
        "            return\n",
        "        \n",
        "        # Abfrage ausf√ºhren\n",
        "        result = ask_question(\n",
        "            question, \n",
        "            top_k=top_k_slider.value,\n",
        "            return_context=show_context_checkbox.value\n",
        "        )\n",
        "\n",
        "query_button.on_click(on_query_button_click)\n",
        "\n",
        "# Widget-Layout\n",
        "query_widgets = widgets.VBox([\n",
        "    widgets.HBox([question_input]),\n",
        "    widgets.HBox([top_k_slider, show_context_checkbox]),\n",
        "    widgets.HBox([query_button]),\n",
        "    query_output\n",
        "])\n",
        "\n",
        "print(\"üîç Interaktive Abfrage-Oberfl√§che:\")\n",
        "display(query_widgets)\n",
        "\n",
        "# Tastenkombination f√ºr Enter\n",
        "def on_question_submit(change):\n",
        "    if change['type'] == 'change' and change['name'] == 'value':\n",
        "        on_query_button_click(None)\n",
        "\n",
        "# Enter-Taste aktivieren (funktioniert nur in einigen Jupyter-Umgebungen)\n",
        "# question_input.observe(on_question_submit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Evaluation\n",
        "\n",
        "## Systematische Bewertung\n",
        "\n",
        "Hier f√ºhren wir eine systematische Evaluation mit dem QA-Datensatz durch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# QA-Datensatz laden\n",
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# QA-Datensatz-Pfad\n",
        "qa_file = \"data/evaluation/qa_pairs.json\"\n",
        "\n",
        "# Beispiel-QA-Datensatz erstellen falls nicht vorhanden\n",
        "if not os.path.exists(qa_file):\n",
        "    print(\"üìù Erstelle Beispiel-QA-Datensatz...\")\n",
        "    \n",
        "    sample_qa_pairs = [\n",
        "        {\n",
        "            \"id\": \"q1\",\n",
        "            \"question\": \"Was ist die maximale Geldbu√üe nach Art. 83 DSGVO?\",\n",
        "            \"expected_answer\": \"Die maximale Geldbu√üe betr√§gt 20 Millionen Euro oder 4% des weltweiten Jahresumsatzes\",\n",
        "            \"category\": \"sanctions\",\n",
        "            \"difficulty\": \"easy\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"q2\", \n",
        "            \"question\": \"Welche Rechte haben betroffene Personen nach der DSGVO?\",\n",
        "            \"expected_answer\": \"Betroffene haben Rechte auf Auskunft, Berichtigung, L√∂schung, Einschr√§nkung der Verarbeitung, Daten√ºbertragbarkeit und Widerspruch\",\n",
        "            \"category\": \"rights\",\n",
        "            \"difficulty\": \"medium\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"q3\",\n",
        "            \"question\": \"Was ist eine Datenschutz-Folgenabsch√§tzung?\",\n",
        "            \"expected_answer\": \"Eine Datenschutz-Folgenabsch√§tzung ist eine Bewertung der Auswirkungen von Datenverarbeitungsvorg√§ngen auf den Schutz personenbezogener Daten\",\n",
        "            \"category\": \"compliance\",\n",
        "            \"difficulty\": \"medium\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"q4\",\n",
        "            \"question\": \"Wann ist eine Einwilligung zur Datenverarbeitung erforderlich?\",\n",
        "            \"expected_answer\": \"Eine Einwilligung ist erforderlich, wenn keine andere Rechtsgrundlage nach Art. 6 DSGVO vorliegt\",\n",
        "            \"category\": \"legal_basis\",\n",
        "            \"difficulty\": \"hard\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"q5\",\n",
        "            \"question\": \"Was sind die Grunds√§tze der Datenverarbeitung nach Art. 5 DSGVO?\",\n",
        "            \"expected_answer\": \"Die Grunds√§tze umfassen Rechtm√§√üigkeit, Transparenz, Zweckbindung, Datenminimierung, Richtigkeit, Speicherbegrenzung und Integrit√§t/Vertraulichkeit\",\n",
        "            \"category\": \"principles\",\n",
        "            \"difficulty\": \"hard\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    # Datei erstellen\n",
        "    Path(qa_file).parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(qa_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(sample_qa_pairs, f, ensure_ascii=False, indent=2)\n",
        "    \n",
        "    print(f\"‚úÖ Beispiel-QA-Datensatz erstellt: {qa_file}\")\n",
        "\n",
        "# QA-Datensatz laden\n",
        "with open(qa_file, 'r', encoding='utf-8') as f:\n",
        "    qa_pairs = json.load(f)\n",
        "\n",
        "print(f\"üìä QA-Datensatz geladen: {len(qa_pairs)} Frage-Antwort-Paare\")\n",
        "\n",
        "# Datensatz-Statistiken\n",
        "df_qa = pd.DataFrame(qa_pairs)\n",
        "print(f\"\\nüìà Datensatz-Statistiken:\")\n",
        "print(f\"  Kategorien: {df_qa['category'].value_counts().to_dict()}\")\n",
        "print(f\"  Schwierigkeitsgrade: {df_qa['difficulty'].value_counts().to_dict()}\")\n",
        "\n",
        "# Erste Fragen anzeigen\n",
        "print(f\"\\nüîç Erste 3 Fragen:\")\n",
        "for i, qa in enumerate(qa_pairs[:3]):\n",
        "    print(f\"  {i+1}. {qa['question']}\")\n",
        "    print(f\"     ‚Üí {qa['expected_answer'][:100]}...\")\n",
        "    print(f\"     Kategorie: {qa['category']}, Schwierigkeit: {qa['difficulty']}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Batch-Evaluation durchf√ºhren\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "def run_evaluation(qa_pairs, pipeline, top_k=5):\n",
        "    \"\"\"F√ºhrt eine Batch-Evaluation durch.\"\"\"\n",
        "    if not pipeline.is_indexed:\n",
        "        print(\"‚ùå Pipeline ist nicht indexiert\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"üîÑ Starte Evaluation mit {len(qa_pairs)} Fragen...\")\n",
        "    \n",
        "    results = []\n",
        "    questions = [qa['question'] for qa in qa_pairs]\n",
        "    \n",
        "    # Batch-Query f√ºr bessere Performance\n",
        "    start_time = time.time()\n",
        "    batch_results = pipeline.batch_query(questions, top_k=top_k, show_progress=True)\n",
        "    total_time = time.time() - start_time\n",
        "    \n",
        "    # Ergebnisse kombinieren\n",
        "    for i, (qa, result) in enumerate(zip(qa_pairs, batch_results)):\n",
        "        eval_result = {\n",
        "            'id': qa['id'],\n",
        "            'question': qa['question'],\n",
        "            'expected_answer': qa['expected_answer'],\n",
        "            'generated_answer': result['answer'],\n",
        "            'category': qa['category'],\n",
        "            'difficulty': qa['difficulty'],\n",
        "            'retrieval_time': result['retrieval_time'],\n",
        "            'generation_time': result['generation_time'],\n",
        "            'total_time': result['total_time'],\n",
        "            'context_count': len(result['context'])\n",
        "        }\n",
        "        results.append(eval_result)\n",
        "    \n",
        "    print(f\"‚úÖ Evaluation abgeschlossen in {total_time:.2f}s\")\n",
        "    print(f\"‚ö° Durchschnittliche Zeit pro Frage: {total_time/len(qa_pairs):.2f}s\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Evaluation ausf√ºhren\n",
        "if 'pipeline' in locals() and pipeline.is_indexed:\n",
        "    print(\"üöÄ F√ºhre Evaluation durch...\")\n",
        "    evaluation_results = run_evaluation(qa_pairs, pipeline)\n",
        "    \n",
        "    if evaluation_results:\n",
        "        # Ergebnisse als DataFrame\n",
        "        df_results = pd.DataFrame(evaluation_results)\n",
        "        \n",
        "        print(f\"\\nüìä Evaluation-Ergebnisse:\")\n",
        "        print(f\"  Fragen bearbeitet: {len(df_results)}\")\n",
        "        print(f\"  Durchschnittliche Retrieval-Zeit: {df_results['retrieval_time'].mean():.2f}s\")\n",
        "        print(f\"  Durchschnittliche Generation-Zeit: {df_results['generation_time'].mean():.2f}s\")\n",
        "        print(f\"  Durchschnittliche Gesamt-Zeit: {df_results['total_time'].mean():.2f}s\")\n",
        "        \n",
        "        # Nach Kategorie gruppieren\n",
        "        category_stats = df_results.groupby('category').agg({\n",
        "            'total_time': 'mean',\n",
        "            'context_count': 'mean'\n",
        "        }).round(2)\n",
        "        \n",
        "        print(f\"\\nüìà Statistiken nach Kategorie:\")\n",
        "        print(category_stats)\n",
        "        \n",
        "        # Erste Ergebnisse anzeigen\n",
        "        print(f\"\\nüîç Erste 3 Ergebnisse:\")\n",
        "        for i, result in enumerate(evaluation_results[:3]):\n",
        "            print(f\"\\n  {i+1}. {result['question']}\")\n",
        "            print(f\"     Erwartet: {result['expected_answer'][:100]}...\")\n",
        "            print(f\"     Generiert: {result['generated_answer'][:100]}...\")\n",
        "            print(f\"     Zeit: {result['total_time']:.2f}s\")\n",
        "else:\n",
        "    print(\"‚ùå Pipeline nicht verf√ºgbar oder nicht indexiert\")\n",
        "    print(\"üí° F√ºhren Sie zuerst die Pipeline-Erstellung und Indexierung aus\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Analyse\n",
        "\n",
        "## Komponenten-Vergleich und Statistiken\n",
        "\n",
        "Hier analysieren wir die Performance verschiedener Komponenten und erstellen Visualisierungen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisierungen erstellen\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plotting-Style setzen\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "def create_performance_plots(df_results):\n",
        "    \"\"\"Erstellt Performance-Visualisierungen.\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('RAG-Pipeline Performance Analyse', fontsize=16)\n",
        "    \n",
        "    # 1. Zeit-Verteilung\n",
        "    axes[0, 0].hist(df_results['total_time'], bins=10, alpha=0.7, edgecolor='black')\n",
        "    axes[0, 0].set_title('Verteilung der Antwortzeiten')\n",
        "    axes[0, 0].set_xlabel('Zeit (Sekunden)')\n",
        "    axes[0, 0].set_ylabel('Anzahl Fragen')\n",
        "    axes[0, 0].axvline(df_results['total_time'].mean(), color='red', linestyle='--', label=f'Mittelwert: {df_results[\"total_time\"].mean():.2f}s')\n",
        "    axes[0, 0].legend()\n",
        "    \n",
        "    # 2. Zeit nach Kategorie\n",
        "    category_times = df_results.groupby('category')['total_time'].mean()\n",
        "    axes[0, 1].bar(category_times.index, category_times.values, alpha=0.7)\n",
        "    axes[0, 1].set_title('Durchschnittliche Antwortzeit nach Kategorie')\n",
        "    axes[0, 1].set_xlabel('Kategorie')\n",
        "    axes[0, 1].set_ylabel('Zeit (Sekunden)')\n",
        "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # 3. Retrieval vs Generation Zeit\n",
        "    axes[1, 0].scatter(df_results['retrieval_time'], df_results['generation_time'], alpha=0.7)\n",
        "    axes[1, 0].set_title('Retrieval-Zeit vs Generation-Zeit')\n",
        "    axes[1, 0].set_xlabel('Retrieval-Zeit (Sekunden)')\n",
        "    axes[1, 0].set_ylabel('Generation-Zeit (Sekunden)')\n",
        "    \n",
        "    # Trendlinie hinzuf√ºgen\n",
        "    z = np.polyfit(df_results['retrieval_time'], df_results['generation_time'], 1)\n",
        "    p = np.poly1d(z)\n",
        "    axes[1, 0].plot(df_results['retrieval_time'], p(df_results['retrieval_time']), \"r--\", alpha=0.8)\n",
        "    \n",
        "    # 4. Kontext-Anzahl nach Schwierigkeit\n",
        "    difficulty_context = df_results.groupby('difficulty')['context_count'].mean()\n",
        "    axes[1, 1].bar(difficulty_context.index, difficulty_context.values, alpha=0.7)\n",
        "    axes[1, 1].set_title('Durchschnittliche Kontext-Anzahl nach Schwierigkeit')\n",
        "    axes[1, 1].set_xlabel('Schwierigkeit')\n",
        "    axes[1, 1].set_ylabel('Anzahl Kontext-Dokumente')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Performance-Analyse\n",
        "if 'evaluation_results' in locals() and evaluation_results:\n",
        "    print(\"üìä Erstelle Performance-Visualisierungen...\")\n",
        "    \n",
        "    import numpy as np\n",
        "    df_results = pd.DataFrame(evaluation_results)\n",
        "    \n",
        "    # Grundlegende Statistiken\n",
        "    print(f\"\\nüìà Performance-Statistiken:\")\n",
        "    print(f\"  Gesamtzeit - Mittelwert: {df_results['total_time'].mean():.2f}s ¬± {df_results['total_time'].std():.2f}s\")\n",
        "    print(f\"  Retrieval-Zeit - Mittelwert: {df_results['retrieval_time'].mean():.2f}s ¬± {df_results['retrieval_time'].std():.2f}s\")\n",
        "    print(f\"  Generation-Zeit - Mittelwert: {df_results['generation_time'].mean():.2f}s ¬± {df_results['generation_time'].std():.2f}s\")\n",
        "    print(f\"  Kontext-Dokumente - Mittelwert: {df_results['context_count'].mean():.1f} ¬± {df_results['context_count'].std():.1f}\")\n",
        "    \n",
        "    # Visualisierungen erstellen\n",
        "    create_performance_plots(df_results)\n",
        "    \n",
        "    # Korrelationsanalyse\n",
        "    print(f\"\\nüîó Korrelationsanalyse:\")\n",
        "    correlation_matrix = df_results[['retrieval_time', 'generation_time', 'total_time', 'context_count']].corr()\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "                square=True, fmt='.2f')\n",
        "    plt.title('Korrelation zwischen Performance-Metriken')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"Interpretation:\")\n",
        "    print(\"- Hohe Korrelation zwischen Retrieval- und Gesamtzeit deutet auf Retrieval-Bottleneck hin\")\n",
        "    print(\"- Niedrige Korrelation zwischen Kontext-Anzahl und Zeit deutet auf effiziente Verarbeitung hin\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Keine Evaluation-Ergebnisse verf√ºgbar\")\n",
        "    print(\"üí° F√ºhren Sie zuerst die Evaluation aus\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Komponenten-Debugging und Analyse\n",
        "def analyze_pipeline_components():\n",
        "    \"\"\"Analysiert die Pipeline-Komponenten im Detail.\"\"\"\n",
        "    if 'pipeline' not in locals():\n",
        "        print(\"‚ùå Pipeline nicht verf√ºgbar\")\n",
        "        return\n",
        "    \n",
        "    print(\"üîç Pipeline-Komponenten-Analyse:\")\n",
        "    \n",
        "    # 1. Chunker-Analyse\n",
        "    print(f\"\\nüìù Chunker-Analyse:\")\n",
        "    chunker_info = pipeline.get_component_info()['chunker']\n",
        "    print(f\"  Typ: {chunker_info}\")\n",
        "    \n",
        "    # Beispiel-Chunking\n",
        "    if os.path.exists(dsgvo_file):\n",
        "        with open(dsgvo_file, 'r', encoding='utf-8') as f:\n",
        "            sample_text = f.read()[:1000]  # Erste 1000 Zeichen\n",
        "        \n",
        "        chunks = pipeline.chunker.chunk_text(sample_text)\n",
        "        print(f\"  Beispiel-Chunks aus ersten 1000 Zeichen: {len(chunks)}\")\n",
        "        print(f\"  Durchschnittliche Chunk-L√§nge: {sum(len(c) for c in chunks) / len(chunks):.0f} Zeichen\")\n",
        "        \n",
        "        if chunks:\n",
        "            print(f\"  Erster Chunk: {chunks[0][:100]}...\")\n",
        "    \n",
        "    # 2. Embedding-Analyse\n",
        "    print(f\"\\nüî¢ Embedding-Analyse:\")\n",
        "    embedding_info = pipeline.get_component_info()['embedding']\n",
        "    print(f\"  Typ: {embedding_info}\")\n",
        "    \n",
        "    # Test-Embedding\n",
        "    test_embedding = pipeline.embedding.embed_query(\"Test-Frage\")\n",
        "    print(f\"  Embedding-Dimension: {len(test_embedding)}\")\n",
        "    print(f\"  Embedding-Typ: {type(test_embedding)}\")\n",
        "    print(f\"  Embedding-Range: [{min(test_embedding):.3f}, {max(test_embedding):.3f}]\")\n",
        "    \n",
        "    # 3. Vector Store-Analyse\n",
        "    print(f\"\\nüóÑÔ∏è  Vector Store-Analyse:\")\n",
        "    vector_store_info = pipeline.get_component_info()['vector_store']\n",
        "    print(f\"  Typ: {vector_store_info}\")\n",
        "    \n",
        "    if hasattr(pipeline.vector_store, 'get_stats'):\n",
        "        stats = pipeline.vector_store.get_stats()\n",
        "        print(f\"  Gespeicherte Dokumente: {stats.get('document_count', 'N/A')}\")\n",
        "        print(f\"  Speichernutzung: {stats.get('memory_usage', 'N/A')}\")\n",
        "    \n",
        "    # 4. Language Model-Analyse\n",
        "    print(f\"\\nü§ñ Language Model-Analyse:\")\n",
        "    llm_info = pipeline.get_component_info()['language_model']\n",
        "    print(f\"  Typ: {llm_info}\")\n",
        "    \n",
        "    # Test-Generation\n",
        "    test_context = [\"Die DSGVO ist eine europ√§ische Datenschutzverordnung.\"]\n",
        "    test_response = pipeline.language_model.generate_with_context(\n",
        "        \"Was ist die DSGVO?\", \n",
        "        test_context\n",
        "    )\n",
        "    print(f\"  Test-Antwort: {test_response[:100]}...\")\n",
        "\n",
        "# Komponenten-Analyse ausf√ºhren\n",
        "if 'pipeline' in locals():\n",
        "    analyze_pipeline_components()\n",
        "else:\n",
        "    print(\"‚ùå Pipeline nicht verf√ºgbar - bitte f√ºhren Sie zuerst die Pipeline-Erstellung aus\")\n",
        "\n",
        "# Speicher-Nutzung anzeigen\n",
        "import psutil\n",
        "import os\n",
        "\n",
        "def show_memory_usage():\n",
        "    \"\"\"Zeigt die aktuelle Speicher-Nutzung an.\"\"\"\n",
        "    process = psutil.Process(os.getpid())\n",
        "    memory_info = process.memory_info()\n",
        "    \n",
        "    print(f\"\\nüíæ Speicher-Nutzung:\")\n",
        "    print(f\"  RSS (Resident Set Size): {memory_info.rss / 1024 / 1024:.1f} MB\")\n",
        "    print(f\"  VMS (Virtual Memory Size): {memory_info.vms / 1024 / 1024:.1f} MB\")\n",
        "    \n",
        "    # System-Speicher\n",
        "    system_memory = psutil.virtual_memory()\n",
        "    print(f\"  System-Speicher: {system_memory.used / 1024 / 1024 / 1024:.1f} GB / {system_memory.total / 1024 / 1024 / 1024:.1f} GB ({system_memory.percent}%)\")\n",
        "\n",
        "try:\n",
        "    show_memory_usage()\n",
        "except ImportError:\n",
        "    print(\"üí° Installieren Sie 'psutil' f√ºr detaillierte Speicher-Analyse: pip install psutil\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ Zusammenfassung und n√§chste Schritte\n",
        "\n",
        "## Was haben wir erreicht?\n",
        "\n",
        "‚úÖ **Erfolgreich implementiert:**\n",
        "- Modulares RAG-System mit austauschbaren Komponenten\n",
        "- Baseline-Konfiguration mit OpenAI-Komponenten\n",
        "- Interaktive Jupyter-Umgebung f√ºr Experimente\n",
        "- Systematische Evaluation mit QA-Datensatz\n",
        "- Performance-Analyse und Visualisierungen\n",
        "\n",
        "## N√§chste Schritte f√ºr das Team\n",
        "\n",
        "### üë• Aufgabenverteilung (Phase 2-4)\n",
        "\n",
        "**Person A - Chunking-Strategien:**\n",
        "- Implementierung von `RecursiveChunker` und `SemanticChunker`\n",
        "- Vergleich verschiedener Chunk-Gr√∂√üen und Overlap-Strategien\n",
        "- Analyse der Auswirkungen auf Retrieval-Qualit√§t\n",
        "\n",
        "**Person B - Embedding-Methoden:**\n",
        "- Integration von `SentenceTransformerEmbedding` und `HuggingFaceEmbedding`\n",
        "- Vergleich verschiedener Embedding-Modelle\n",
        "- Optimierung f√ºr deutsche DSGVO-Texte\n",
        "\n",
        "**Person C - Vector Stores & Retrieval:**\n",
        "- Implementierung von `ChromaVectorStore` und `FAISSVectorStore`\n",
        "- Optimierung von Similarity-Metriken\n",
        "- Skalierbarkeits-Tests\n",
        "\n",
        "**Person D - Language Models & Generation:**\n",
        "- Integration von `OllamaLanguageModel` und `HuggingFaceLanguageModel`\n",
        "- Prompt-Engineering f√ºr bessere DSGVO-Antworten\n",
        "- Evaluation der Antwortqualit√§t\n",
        "\n",
        "## üí° Tipps f√ºr die Weiterarbeit\n",
        "\n",
        "1. **Komponenten-Entwicklung:** Nutzen Sie die bestehenden Basisklassen als Vorlage\n",
        "2. **Testing:** Verwenden Sie das Notebook f√ºr schnelle Prototyping-Zyklen\n",
        "3. **Evaluation:** Erweitern Sie den QA-Datensatz f√ºr Ihre spezifischen Komponenten\n",
        "4. **Dokumentation:** Aktualisieren Sie die README.md mit Ihren Erkenntnissen\n",
        "\n",
        "## üîß Debugging-Tipps\n",
        "\n",
        "- Verwenden Sie `analyze_pipeline_components()` f√ºr detaillierte Komponenten-Analyse\n",
        "- Nutzen Sie `show_memory_usage()` zur √úberwachung der Ressourcen\n",
        "- Aktivieren Sie `return_context=True` bei Abfragen f√ºr besseres Debugging\n",
        "\n",
        "## üìä Experimentier-Framework\n",
        "\n",
        "Das Notebook bietet alles was Sie brauchen:\n",
        "- ‚úÖ Konfiguration verschiedener Komponenten\n",
        "- ‚úÖ Batch-Evaluation f√ºr systematische Tests\n",
        "- ‚úÖ Visualisierungen f√ºr Performance-Analyse\n",
        "- ‚úÖ Interaktive Abfrage-Oberfl√§che\n",
        "\n",
        "**Viel Erfolg bei Ihrer Forschung! üöÄ**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ResearchRAG - Modulares RAG-System\n",
        "\n",
        "## Projekt√ºbersicht\n",
        "\n",
        "Dieses Notebook dient als Steuerungszentrale f√ºr das modulare RAG-System. Es erm√∂glicht:\n",
        "\n",
        "- **Einfache Konfiguration** verschiedener Pipeline-Komponenten\n",
        "- **Schnelle Experimente** mit unterschiedlichen Chunking-, Embedding-, Vector Store- und LLM-Strategien\n",
        "- **Evaluierung** der Pipeline-Performance\n",
        "- **Vergleich** verschiedener Konfigurationen\n",
        "\n",
        "## Verwendung\n",
        "\n",
        "1. **Konfiguration w√§hlen** (Baseline oder Custom)\n",
        "2. **Dokumente indexieren** (DSGVO-Text)\n",
        "3. **Queries ausf√ºhren** und Ergebnisse analysieren\n",
        "4. **Experimente durchf√ºhren** mit verschiedenen Komponenten\n",
        "\n",
        "---\n",
        "\n",
        "**Autoren:** FOM Research Team  \n",
        "**Projekt:** Big Data Analyse - RAG-System Evaluierung  \n",
        "**Datum:** Januar 2025\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installiere erforderliche Pakete (nur in Google Colab)\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def install_packages():\n",
        "    \"\"\"Installiert alle erforderlichen Pakete f√ºr Google Colab.\"\"\"\n",
        "    packages = [\n",
        "        \"openai>=1.10.0\",\n",
        "        \"sentence-transformers>=2.2.0\",\n",
        "        \"chromadb>=0.4.0\",\n",
        "        \"faiss-cpu>=1.7.4\",\n",
        "        \"scikit-learn>=1.0.0\",\n",
        "        \"numpy>=1.21.0\",\n",
        "        \"pandas>=1.3.0\",\n",
        "        \"python-dotenv>=0.19.0\",\n",
        "        \"tqdm>=4.64.0\"\n",
        "    ]\n",
        "    \n",
        "    for package in packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "            print(f\"‚úì {package} installiert\")\n",
        "        except subprocess.CalledProcessError:\n",
        "            print(f\"‚úó Fehler bei Installation von {package}\")\n",
        "\n",
        "# Nur in Google Colab ausf√ºhren\n",
        "if 'google.colab' in sys.modules:\n",
        "    print(\"Google Colab erkannt - installiere Pakete...\")\n",
        "    install_packages()\n",
        "    \n",
        "    # Google Drive mounten f√ºr Persistierung\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    print(\"‚úì Setup f√ºr Google Colab abgeschlossen\")\n",
        "else:\n",
        "    print(\"Lokale Umgebung erkannt - verwende requirements.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports und Setup\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List\n",
        "\n",
        "# Warnings unterdr√ºcken\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Lokale Imports\n",
        "sys.path.append('.')\n",
        "from src.config.pipeline_configs import PipelineConfig, get_baseline_config, get_alternative_configs\n",
        "from src.core.rag_pipeline import RAGPipeline\n",
        "from src.core.component_loader import ComponentLoader\n",
        "\n",
        "# Umgebungsvariablen\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "print(\"‚úì Alle Module erfolgreich importiert\")\n",
        "print(f\"‚úì Python Version: {sys.version}\")\n",
        "print(f\"‚úì Arbeitsverzeichnis: {os.getcwd()}\")\n",
        "\n",
        "# API-Schl√ºssel pr√ºfen\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    print(\"‚ö†Ô∏è  OPENAI_API_KEY nicht gesetzt!\")\n",
        "    print(\"   Setzen Sie Ihren API-Schl√ºssel:\")\n",
        "    print(\"   os.environ['OPENAI_API_KEY'] = 'your-api-key-here'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 1. Pipeline-Konfiguration\n",
        "\n",
        "W√§hlen Sie eine der verf√ºgbaren Konfigurationen oder erstellen Sie eine benutzerdefinierte Konfiguration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.1 Verf√ºgbare Konfigurationen anzeigen\n",
        "def show_available_configs():\n",
        "    \"\"\"Zeigt alle verf√ºgbaren Pipeline-Konfigurationen.\"\"\"\n",
        "    configs = get_alternative_configs()\n",
        "    \n",
        "    print(\"üîß Verf√ºgbare Pipeline-Konfigurationen:\\n\")\n",
        "    \n",
        "    for name, config in configs.items():\n",
        "        pipeline_info = config.get_pipeline_info()\n",
        "        component_types = config.get_component_types()\n",
        "        \n",
        "        print(f\"üìã {name.upper()}\")\n",
        "        print(f\"   Beschreibung: {pipeline_info.get('description', 'Keine Beschreibung')}\")\n",
        "        print(f\"   Chunker: {component_types['chunker']}\")\n",
        "        print(f\"   Embedding: {component_types['embedding']}\")\n",
        "        print(f\"   Vector Store: {component_types['vector_store']}\")\n",
        "        print(f\"   Language Model: {component_types['language_model']}\")\n",
        "        print()\n",
        "\n",
        "show_available_configs()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.2 Konfiguration w√§hlen\n",
        "# √Ñndern Sie hier die gew√ºnschte Konfiguration\n",
        "SELECTED_CONFIG = \"baseline\"  # Optionen: \"baseline\", \"recursive_chunker\", \"sentence_transformer\", \"chroma_store\", \"gpt4_model\"\n",
        "\n",
        "# Konfiguration laden\n",
        "configs = get_alternative_configs()\n",
        "if SELECTED_CONFIG not in configs:\n",
        "    print(f\"‚ùå Konfiguration '{SELECTED_CONFIG}' nicht gefunden!\")\n",
        "    print(f\"Verf√ºgbare Optionen: {list(configs.keys())}\")\n",
        "    selected_config = get_baseline_config()\n",
        "else:\n",
        "    selected_config = configs[SELECTED_CONFIG]\n",
        "\n",
        "print(f\"‚úÖ Gew√§hlte Konfiguration: {SELECTED_CONFIG}\")\n",
        "print(f\"üìù Beschreibung: {selected_config.get_pipeline_info().get('description', 'Keine Beschreibung')}\")\n",
        "print(\"\\nüîß Komponenten:\")\n",
        "for component, type_name in selected_config.get_component_types().items():\n",
        "    print(f\"   {component}: {type_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Pipeline initialisieren\n",
        "\n",
        "Erstellen Sie die RAG-Pipeline mit der gew√§hlten Konfiguration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.1 Pipeline erstellen\n",
        "try:\n",
        "    # API-Schl√ºssel setzen falls noch nicht vorhanden\n",
        "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "        # Beispiel f√ºr API-Schl√ºssel setzen (ersetzen Sie durch Ihren echten Schl√ºssel)\n",
        "        # os.environ['OPENAI_API_KEY'] = 'sk-your-api-key-here'\n",
        "        print(\"‚ö†Ô∏è  Bitte setzen Sie Ihren OpenAI API-Schl√ºssel!\")\n",
        "        print(\"   os.environ['OPENAI_API_KEY'] = 'sk-your-api-key-here'\")\n",
        "    \n",
        "    # Pipeline erstellen\n",
        "    print(\"üöÄ Erstelle RAG-Pipeline...\")\n",
        "    pipeline = RAGPipeline(selected_config)\n",
        "    \n",
        "    print(\"‚úÖ Pipeline erfolgreich erstellt!\")\n",
        "    print(f\"üìä Pipeline-Info: {pipeline.get_pipeline_info()}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Fehler beim Erstellen der Pipeline: {e}\")\n",
        "    print(\"üí° Tipp: √úberpr√ºfen Sie Ihren OpenAI API-Schl√ºssel\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. Dokumente indexieren\n",
        "\n",
        "Laden und indexieren Sie die DSGVO-Dokumente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.1 DSGVO-Dokument laden und indexieren\n",
        "try:\n",
        "    # Dokumentpfad\n",
        "    dsgvo_path = \"data/raw/dsgvo.txt\"\n",
        "    \n",
        "    if not os.path.exists(dsgvo_path):\n",
        "        print(f\"‚ùå DSGVO-Datei nicht gefunden: {dsgvo_path}\")\n",
        "        print(\"üí° Stellen Sie sicher, dass die DSGVO-Datei im data/raw/ Verzeichnis liegt\")\n",
        "    else:\n",
        "        # Dokument laden\n",
        "        print(\"üìñ Lade DSGVO-Dokument...\")\n",
        "        documents = pipeline.load_documents_from_file(dsgvo_path)\n",
        "        print(f\"‚úÖ {len(documents)} Dokument(e) geladen\")\n",
        "        print(f\"üìè Dokumentl√§nge: {len(documents[0]):,} Zeichen\")\n",
        "        \n",
        "        # Indexierung\n",
        "        print(\"\\nüîÑ Starte Indexierung...\")\n",
        "        start_time = time.time()\n",
        "        \n",
        "        indexing_stats = pipeline.index_documents(documents, show_progress=True)\n",
        "        \n",
        "        end_time = time.time()\n",
        "        \n",
        "        print(f\"\\n‚úÖ Indexierung abgeschlossen!\")\n",
        "        print(f\"‚è±Ô∏è  Gesamtzeit: {end_time - start_time:.2f} Sekunden\")\n",
        "        print(f\"üìä Statistiken:\")\n",
        "        for key, value in indexing_stats.items():\n",
        "            if isinstance(value, float):\n",
        "                print(f\"   {key}: {value:.2f}\")\n",
        "            else:\n",
        "                print(f\"   {key}: {value}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Fehler beim Indexieren: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. RAG-System testen\n",
        "\n",
        "F√ºhren Sie Beispiel-Queries aus und analysieren Sie die Ergebnisse.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.1 Beispiel-Queries definieren\n",
        "sample_questions = [\n",
        "    \"Was ist die maximale Geldbu√üe nach Art. 83 DSGVO?\",\n",
        "    \"Welche Rechtsgrundlagen f√ºr die Verarbeitung gibt es?\",\n",
        "    \"Wie l√§uft das Verfahren bei einer Datenschutz-Folgenabsch√§tzung ab?\",\n",
        "    \"Welche Rechte haben betroffene Personen?\",\n",
        "    \"Was sind die Grunds√§tze der Datenverarbeitung?\"\n",
        "]\n",
        "\n",
        "print(\"üìù Beispiel-Fragen:\")\n",
        "for i, question in enumerate(sample_questions, 1):\n",
        "    print(f\"{i}. {question}\")\n",
        "\n",
        "print(f\"\\nüí° Sie k√∂nnen auch eigene Fragen in der n√§chsten Zelle stellen!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.2 Einzelne Query ausf√ºhren\n",
        "def ask_question(question: str, show_context: bool = False):\n",
        "    \"\"\"F√ºhrt eine einzelne Query aus und zeigt das Ergebnis.\"\"\"\n",
        "    print(f\"‚ùì Frage: {question}\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    try:\n",
        "        # Query ausf√ºhren\n",
        "        result = pipeline.query(question, return_context=show_context)\n",
        "        \n",
        "        print(f\"üí¨ Antwort:\")\n",
        "        print(result['answer'])\n",
        "        print()\n",
        "        \n",
        "        print(f\"üìä Metadaten:\")\n",
        "        print(f\"   ‚è±Ô∏è  Query-Zeit: {result['query_time']:.2f}s\")\n",
        "        print(f\"   üîç Gefundene Kontexte: {result['retrieval_count']}\")\n",
        "        print(f\"   üîß Pipeline: {result['pipeline_config']}\")\n",
        "        \n",
        "        if show_context and 'retrieved_contexts' in result:\n",
        "            print(f\"\\nüìñ Gefundene Kontexte:\")\n",
        "            for i, context in enumerate(result['retrieved_contexts'], 1):\n",
        "                print(f\"\\n   Kontext {i} (Score: {context['score']:.3f}):\")\n",
        "                print(f\"   {context['text'][:200]}...\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Fehler bei der Query: {e}\")\n",
        "    \n",
        "    print(\"=\" * 80)\n",
        "\n",
        "# Beispiel-Query ausf√ºhren\n",
        "ask_question(sample_questions[0], show_context=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.3 Eigene Frage stellen\n",
        "# √Ñndern Sie hier Ihre eigene Frage\n",
        "CUSTOM_QUESTION = \"Welche Pflichten haben Auftragsverarbeiter?\"\n",
        "\n",
        "print(\"üéØ Ihre eigene Frage:\")\n",
        "ask_question(CUSTOM_QUESTION, show_context=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.4 Batch-Verarbeitung aller Beispiel-Fragen\n",
        "print(\"üîÑ Verarbeite alle Beispiel-Fragen...\")\n",
        "batch_results = pipeline.batch_query(sample_questions, show_progress=True)\n",
        "\n",
        "print(\"\\nüìä Zusammenfassung der Ergebnisse:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "total_time = sum(result['query_time'] for result in batch_results)\n",
        "avg_time = total_time / len(batch_results)\n",
        "\n",
        "for i, (question, result) in enumerate(zip(sample_questions, batch_results), 1):\n",
        "    print(f\"\\n{i}. {question}\")\n",
        "    print(f\"   üí¨ Antwort: {result['answer'][:100]}...\")\n",
        "    print(f\"   ‚è±Ô∏è  Zeit: {result['query_time']:.2f}s\")\n",
        "    print(f\"   üîç Kontexte: {result['retrieval_count']}\")\n",
        "\n",
        "print(f\"\\nüìà Gesamt-Statistiken:\")\n",
        "print(f\"   üéØ Verarbeitete Fragen: {len(batch_results)}\")\n",
        "print(f\"   ‚è±Ô∏è  Gesamtzeit: {total_time:.2f}s\")\n",
        "print(f\"   üìä Durchschnittliche Zeit: {avg_time:.2f}s\")\n",
        "print(f\"   üöÄ Fragen pro Sekunde: {len(batch_results)/total_time:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Pipeline-Analyse und Debugging\n",
        "\n",
        "Analysieren Sie die Pipeline-Komponenten und deren Verhalten.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.1 Detaillierte Pipeline-Informationen\n",
        "print(\"üîç Detaillierte Pipeline-Analyse:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Pipeline-Info\n",
        "pipeline_info = pipeline.get_pipeline_info()\n",
        "print(f\"üìã Pipeline-Informationen:\")\n",
        "for key, value in pipeline_info.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "\n",
        "# Komponenten-Info\n",
        "component_info = pipeline.get_component_info()\n",
        "print(f\"üß© Komponenten-Details:\")\n",
        "\n",
        "for component_name, info in component_info.items():\n",
        "    print(f\"\\nüì¶ {component_name.upper()}:\")\n",
        "    print(f\"   Typ: {info['type']}\")\n",
        "    print(f\"   Konfiguration:\")\n",
        "    for key, value in info['config'].items():\n",
        "        print(f\"      {key}: {value}\")\n",
        "    \n",
        "    if 'stats' in info and info['stats']:\n",
        "        print(f\"   Statistiken:\")\n",
        "        for key, value in info['stats'].items():\n",
        "            print(f\"      {key}: {value}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.2 Chunking-Analyse\n",
        "print(\"üìÑ Chunking-Analyse:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Beispiel-Text chunken\n",
        "sample_text = \"\"\"\n",
        "Art. 1 Gegenstand und Ziele\n",
        "\n",
        "(1) Diese Verordnung enth√§lt Vorschriften zum Schutz nat√ºrlicher Personen bei der Verarbeitung personenbezogener Daten und zum freien Verkehr solcher Daten.\n",
        "\n",
        "(2) Diese Verordnung sch√ºtzt die Grundrechte und Grundfreiheiten nat√ºrlicher Personen und insbesondere deren Recht auf Schutz personenbezogener Daten.\n",
        "\n",
        "(3) Der freie Verkehr personenbezogener Daten in der Union darf aus Gr√ºnden des Schutzes nat√ºrlicher Personen bei der Verarbeitung personenbezogener Daten weder eingeschr√§nkt noch untersagt werden.\n",
        "\"\"\"\n",
        "\n",
        "chunks = pipeline.chunker.chunk_text(sample_text.strip())\n",
        "\n",
        "print(f\"üìù Original-Text ({len(sample_text)} Zeichen):\")\n",
        "print(sample_text[:200] + \"...\")\n",
        "\n",
        "print(f\"\\nüî™ Chunks ({len(chunks)} St√ºck):\")\n",
        "for i, chunk in enumerate(chunks, 1):\n",
        "    print(f\"\\nChunk {i} ({len(chunk)} Zeichen):\")\n",
        "    print(f\"'{chunk[:100]}...'\")\n",
        "\n",
        "print(f\"\\nüìä Chunking-Statistiken:\")\n",
        "print(f\"   Anzahl Chunks: {len(chunks)}\")\n",
        "print(f\"   Durchschnittliche Chunk-L√§nge: {sum(len(c) for c in chunks) / len(chunks):.1f} Zeichen\")\n",
        "print(f\"   K√ºrzester Chunk: {min(len(c) for c in chunks)} Zeichen\")\n",
        "print(f\"   L√§ngster Chunk: {max(len(c) for c in chunks)} Zeichen\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. Experimentieren mit verschiedenen Konfigurationen\n",
        "\n",
        "Testen Sie verschiedene Pipeline-Konfigurationen und vergleichen Sie die Ergebnisse.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6.1 Vergleich verschiedener Konfigurationen\n",
        "def compare_configurations(test_question: str = \"Was ist die maximale Geldbu√üe nach Art. 83 DSGVO?\"):\n",
        "    \"\"\"Vergleicht verschiedene Pipeline-Konfigurationen.\"\"\"\n",
        "    \n",
        "    configs_to_test = [\"baseline\"]  # Nur Baseline f√ºr jetzt, da andere Komponenten noch nicht implementiert\n",
        "    \n",
        "    print(f\"üî¨ Experiment: Vergleich verschiedener Konfigurationen\")\n",
        "    print(f\"‚ùì Test-Frage: {test_question}\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for config_name in configs_to_test:\n",
        "        print(f\"\\nüß™ Teste Konfiguration: {config_name}\")\n",
        "        \n",
        "        try:\n",
        "            # Konfiguration laden\n",
        "            configs = get_alternative_configs()\n",
        "            config = configs[config_name]\n",
        "            \n",
        "            # Neue Pipeline erstellen\n",
        "            test_pipeline = RAGPipeline(config)\n",
        "            \n",
        "            # Dokument indexieren (falls noch nicht geschehen)\n",
        "            if not test_pipeline.is_indexed:\n",
        "                documents = test_pipeline.load_documents_from_file(\"data/raw/dsgvo.txt\")\n",
        "                test_pipeline.index_documents(documents, show_progress=False)\n",
        "            \n",
        "            # Query ausf√ºhren\n",
        "            start_time = time.time()\n",
        "            result = test_pipeline.query(test_question)\n",
        "            end_time = time.time()\n",
        "            \n",
        "            results[config_name] = {\n",
        "                'answer': result['answer'],\n",
        "                'query_time': result['query_time'],\n",
        "                'retrieval_count': result['retrieval_count'],\n",
        "                'components': config.get_component_types()\n",
        "            }\n",
        "            \n",
        "            print(f\"   ‚úÖ Erfolgreich getestet\")\n",
        "            print(f\"   ‚è±Ô∏è  Zeit: {result['query_time']:.2f}s\")\n",
        "            print(f\"   üí¨ Antwort: {result['answer'][:100]}...\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Fehler: {e}\")\n",
        "            results[config_name] = {'error': str(e)}\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üìä Vergleichsergebnisse:\")\n",
        "    \n",
        "    for config_name, result in results.items():\n",
        "        if 'error' not in result:\n",
        "            print(f\"\\nüîß {config_name.upper()}:\")\n",
        "            print(f\"   ‚è±Ô∏è  Query-Zeit: {result['query_time']:.2f}s\")\n",
        "            print(f\"   üîç Retrieval-Count: {result['retrieval_count']}\")\n",
        "            print(f\"   üß© Komponenten: {result['components']}\")\n",
        "            print(f\"   üí¨ Antwort: {result['answer'][:150]}...\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Experiment ausf√ºhren\n",
        "experiment_results = compare_configurations()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 7. N√§chste Schritte\n",
        "\n",
        "Dieses Notebook bietet eine solide Basis f√ºr Ihre RAG-System-Experimente. Hier sind die n√§chsten Schritte f√ºr Ihre Forschung:\n",
        "\n",
        "### F√ºr Person A (Chunking-Strategien):\n",
        "- Implementieren Sie `RecursiveChunker` in `src/components/chunkers/recursive_chunker.py`\n",
        "- Experimentieren Sie mit verschiedenen Chunk-Gr√∂√üen und √úberlappungen\n",
        "- Testen Sie semantisches Chunking\n",
        "\n",
        "### F√ºr Person B (Embedding-Verfahren):\n",
        "- Implementieren Sie `SentenceTransformerEmbedding` in `src/components/embeddings/sentence_transformer_embedding.py`\n",
        "- Vergleichen Sie verschiedene Embedding-Modelle\n",
        "- Analysieren Sie die Embedding-Qualit√§t\n",
        "\n",
        "### F√ºr Person C (Vector Stores & Retrieval):\n",
        "- Implementieren Sie `ChromaVectorStore` in `src/components/vector_stores/chroma_vector_store.py`\n",
        "- Testen Sie verschiedene √Ñhnlichkeitsmetriken\n",
        "- Optimieren Sie Retrieval-Parameter\n",
        "\n",
        "### F√ºr Person D (Language Models & Generation):\n",
        "- Implementieren Sie lokale LLM-Integration (Ollama)\n",
        "- Experimentieren Sie mit verschiedenen Prompt-Strategien\n",
        "- Optimieren Sie Generation-Parameter\n",
        "\n",
        "### Gemeinsame Aufgaben:\n",
        "- Erstellen Sie QA-Datens√§tze f√ºr systematische Evaluierung\n",
        "- Implementieren Sie Evaluierungsmetriken\n",
        "- Dokumentieren Sie Ihre Experimente\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
